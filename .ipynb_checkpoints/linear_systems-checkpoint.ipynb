{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Solution of Systems of Linear Equations\n",
    "\n",
    "## Background\n",
    "\n",
    "### Engineering Problems\n",
    "\n",
    "We can write many engineering problems as systems of linear equations, which happen to have many ways of being solved numerically. Here are some general engineering problems that can be written as linear systems:\n",
    "\n",
    "1. Truss Problems (Newton's Laws)\n",
    "2. Circuit Problems (Kirchoff's Laws)\n",
    "3. Motion of Objects with Internal Connections (Newton's laws - written as ODEs)\n",
    "4. Stress/Strain/Deformation (PDEs)\n",
    "5. Fluid Motion (PDEs)\n",
    "\n",
    "### Cramer's Rule\n",
    "\n",
    "When you have a smaller problem, you can usually use Cramer's Rule to solve it. The problem we want to solve is:\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\n",
    "\\label{eq1}\\tag{1} $\n",
    "\n",
    "Cramer's Rule States:\n",
    "\n",
    "$ \\large x_0 =  \\frac{\\begin{vmatrix} b_0 & a_{01} & a_{02} \\\\ b_1 & a_{11} & a_{12} \\\\ b_2 & a_{21} & a_{22} \\end{vmatrix}}{\\begin{vmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{vmatrix} }~~~  x_1 =  \\frac{\\begin{vmatrix} a_{00} & b_0 & a_{02} \\\\ a_{10} & b_1 & a_{12} \\\\ a_{20} & b_2 & a_{22} \\end{vmatrix}}{\\begin{vmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{vmatrix} } ~~~  x_2 =  \\frac{\\begin{vmatrix} a_{00} & a_{01} & b_0 \\\\ a_{10} & a_{11} & b_1 \\\\ a_{20} & a_{21} & b_2 \\end{vmatrix}}{\\begin{vmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{vmatrix} }  \\label{eq2}\\tag{2} $\n",
    "\n",
    "I will try to stick with $0$ as the starting subscript. Since we are coding in python that will work much better for the arrays and loop bounds.\n",
    "\n",
    "### Triangular Forms\n",
    "\n",
    "#### Upper Triangulars\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & a_{01} & a_{02} \\\\ 0 & a_{11} & a_{12} \\\\ 0 & 0 & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\\label{eq3}\\tag{3}$\n",
    "\n",
    "An upper triangular problem like this can be solved using *back substitution*.\n",
    "\n",
    "Although not as common another upper triangular can be written as:\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & 0 \\\\ a_{20} & 0 & 0 \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\\label{eq4}\\tag{4}$\n",
    "\n",
    "#### Lower Triangulars\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & 0 & 0 \\\\ a_{10} & a_{11} & 0 \\\\ a_{20} & a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\\label{eq5}\\tag{5}$\n",
    "\n",
    "And yet again there is an alternative (somewhat uncommon) way of writing another lower triangular:\n",
    "\n",
    "$ \\large \\begin{bmatrix} 0 & 0 & a_{02} \\\\ 0 & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\\label{eq6}\\tag{6}$\n",
    "\n",
    "#### Diagonal Matrix\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & 0 & 0 \\\\ 0 & a_{11} & 0 \\\\ 0 & 0 & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix}\\label{eq7}\\tag{7}$\n",
    "\n",
    "A diagonal matrix is easy to solve because $ \\large x_i = \\frac{b_i}{a_{ii}}$.\n",
    "\n",
    "A very special diagonal matrix is the identity matrix:\n",
    "\n",
    "$ \\large I = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "\n",
    "\n",
    "### Back Substitution\n",
    "\n",
    "The technique known as *back substitution* can be used to find $[x]$ in the case of Eq.($\\ref{eq3}$) - which we will now demonstrate. For Eq.($\\ref{eq3}$) from the last row of the matrix we can write:\n",
    "\n",
    "$\\large x_2 = \\frac{b_2}{a_{22}} \\label{eq8}\\tag{8}$. Since $x_2$ is now known, we can find $x_1$ as\n",
    "\n",
    "$\\large x_1 = \\frac{b_1 - a_{12} x_2}{a_{11}} \\label{eq9}\\tag{9} $ and now we can find $x_0$ as\n",
    "\n",
    "$\\large x_0 = \\frac{b_0 - a_{01} x_1 - a_{02} x_2}{a_{00}} = \\frac{b_0 - (a_{01} x_1 + a_{02} x_2)}{a_{00}} = \\frac{b_0 - \\sum\\limits_{j=1}^{2} a_{0j} x_j}{a_{00}} \\label{eq10}\\tag{10} $\n",
    "\n",
    "For that matter, $x_1$ could have been written as \n",
    "\n",
    "$\\large x_1 = \\frac{b_1 - \\sum\\limits_{j=2}^{2} a_{1j} x_j}{a_{11}} \\label{eq11}\\tag{11} $\n",
    "\n",
    "Of course there will be only one term in the summation here. So we now almost have an algorithm... we just need to generalize for $x_i$ and determine the generalized summation limits. We will just use the simple calculation of $x_2$ to get the process started and that the size of the problem/martrix is $nxn$.\n",
    "\n",
    "In looking at Eq.($\\ref{eq10}$) where $i=0$ it seems that *j* ranges from $i+1 = 1$ to $n-1 = 2$ So the general form of the expression for finding $x_i$ would be\n",
    "\n",
    "$\\large x_i =  \\frac{b_i - \\sum\\limits_{j=i+1}^{n-1} a_{ij} x_j}{a_{ii}}~~~ i=n-2, n-3, ...0 \\label{eq12}\\tag{12} $\n",
    "\n",
    "Again, this assumes that we have already calculated:\n",
    "\n",
    "$\\large x_{n-1} = \\frac{b_{n-1}}{a_{n-1,n-1}} \\label{eq13}\\tag{13}$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gauss Elimination (including Normalization and Back Substitution)\n",
    "\n",
    "Returning to the original problem:\n",
    "\n",
    "$ \\large \\begin{bmatrix} a_{00} & a_{01} & a_{02} \\\\ a_{10} & a_{11} & a_{12} \\\\ a_{20} & a_{21} & a_{22} \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} b_0 \\\\ b_1 \\\\ b_2 \\end{bmatrix} $\n",
    "\n",
    "Now we will demonstrate the Gauss elimination technique with an example. The *pivots* are the diagonal elements and a *pivot* row is a row containing a pivot. The process starts at the top row, eliminates all elements below the current pivot, then moves to the next row.\n",
    "\n",
    "$ \\large x_1 - 3 x_2 + x_3 = 4 $\n",
    "\n",
    "$ \\large 2 x_1 - 8 x_2 + 8 x_3 = -2 $\n",
    "\n",
    "$ \\large -6 x_1 + 3 x_2 - 15  x_3 = 9 $\n",
    "\n",
    "Or written in matrix form.\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 \\\\ 2 & -8 & 8 \\\\ -6 & 3 & -15 \\end{bmatrix} \\begin{bmatrix} x_0 \\\\ x_1 \\\\ x_2 \\end{bmatrix} = \\begin{bmatrix} 4 \\\\ -2 \\\\ 9 \\end{bmatrix} $\n",
    "We usually write this in an abbreviated form that is convenient for Gauss Elimination: \n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 2 & -8 & 8 & -2 \\\\ -6 & 3 & -15 & 9 \\end{bmatrix}$\n",
    "\n",
    "This is the *augmented matrix* form. It's convenient because we are going to do operations on each row (including the RHS vector).\n",
    "\n",
    "### Forward Elimination\n",
    "\n",
    "The process is basically this: multiply the pivot row by negative of the element below the pivot you want to eliminate... then add this multiplied pivot row to the row in which you are eliminating an element... the result of this addition is the new row. For example if the pivot is the *1* in position $a_{00}$, then to get rid of the *2* in position $a_{10}$, we would multiply row *0* by *-2* then add that to row *1*.\n",
    "\n",
    "$ \\large -2 R_0 + R_1 = R_{1}^{'} $\n",
    "\n",
    "$ \\large -2 \\begin{bmatrix} 1 & -3 & 1 & 4 \\end{bmatrix} = \\begin{bmatrix} -2 & 6 & -2 & -8 \\end{bmatrix} \\rightarrow \\begin{bmatrix} -2 & 6 & -2 & -8 \\end{bmatrix} + \\begin{bmatrix} 2 & -8 & 8 & -2 \\end{bmatrix} = \\begin{bmatrix} 0 & -2 & 6 & -10 \\end{bmatrix} = R_{1}^{'}$\n",
    "\n",
    "Now the augmented matrix looks as follows:\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 0 & -2 & 6 & -10 \\\\ -6 & 3 & -15 & 9 \\end{bmatrix}$\n",
    "\n",
    "Now we can eliminate the *-6* in $R_2$ by the following operation: $ 6 R_0 + R_2 = R_{2}^{'} $, which gives:\n",
    "\n",
    "$ \\large 6 \\begin{bmatrix} 1 & -3 & 1 & 4 \\end{bmatrix} = \\begin{bmatrix} 6 & -18 & 6 & 24 \\end{bmatrix} \\rightarrow \\begin{bmatrix} 6 & -18 & 6 & 24 \\end{bmatrix} + \\begin{bmatrix} -6 & 3 & 15 & 9 \\end{bmatrix} = \\begin{bmatrix} 0 & -15 & -9 & 33 \\end{bmatrix} = R_{2}^{'}$\n",
    "\n",
    "So the new version of the augmented matrix looks like:\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 0 & -2 & 6 & -10 \\\\ 0 & -15 & -9 & 33 \\end{bmatrix}$\n",
    "\n",
    "The next step is use $R_{1}^{'}$ as the pivot row, but before doing that we *normalize* $R_{1}^{'}$... which means to make the pivot element - the *-2* - a *1* ... which we can do by taking $\\frac{R_{1}^{'}}{-2} = \\begin{bmatrix} 0 & 1 & -3 & 5 \\end{bmatrix}$ which leaves our matrix as\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 0 & 1 & -3 & 5 \\\\ 0 & -15 & -9 & 33 \\end{bmatrix}$\n",
    "\n",
    "Now eliminate the *-15* below the current pivot by $ 15 R_{1}^{'} + R_{2}^{'} $, which gives:\n",
    "\n",
    "$ \\large 15 \\begin{bmatrix} 0 & 1 & -3 & 5 \\end{bmatrix} = \\begin{bmatrix} 0 & 15 & -45 & 75 \\end{bmatrix} \\rightarrow \\begin{bmatrix} 0 & 15 & -45 & 75 \\end{bmatrix} + \\begin{bmatrix} 0 & -15 & -9 & 33 \\end{bmatrix} = \\begin{bmatrix} 0 & 0 & -54 & 108 \\end{bmatrix} = R_{2}^{''}$\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 0 & 1 & -3 & 5 \\\\ 0 & 0 & -54 & 108 \\end{bmatrix}$\n",
    "\n",
    "Let's go ahead and normalize the last row - $\\frac{R_{2}^{''}}{-54} = \\begin{bmatrix} 0 & 0 & 1 & -2 \\end{bmatrix}$.\n",
    "\n",
    "$ \\large \\begin{bmatrix} 1 & -3 & 1 & 4 \\\\ 0 & 1 & -3 & 5 \\\\ 0 & 0 & 1 & -2 \\end{bmatrix}$\n",
    "\n",
    "At this point *forward elimination* is complete!\n",
    "\n",
    "### Back Substitution\n",
    "\n",
    "The equation form of the last row ($R_{2}^{''}$ is:\n",
    "\n",
    "$ \\large (1)x_2 = -2 \\rightarrow x_2 = -2 $\n",
    "\n",
    "Allowing us to solve the equation form of $R_{1}^{''}$:\n",
    "\n",
    "$ \\large (1) x_1 + (-3)(-2) = 5 \\rightarrow x_1 = -1$\n",
    "\n",
    "And finally we can solve the equation from $R_{0}^{'}$ as\n",
    "\n",
    "$ \\large (1) x_0 + (-3)(-1) + (1)(-2) = 4  \\rightarrow x_0 = 3$\n",
    "\n",
    "Giving the final solution as:\n",
    "\n",
    "$ \\large x = \\begin{bmatrix} 3 \\\\ -1 \\\\ -2 \\end{bmatrix}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
